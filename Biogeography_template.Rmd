---
title: "Biogeography Explore"
author: "Brooke Rose"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    theme: journal
    highlight: espresso
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cache=TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.width=12, fig.height=8) 
```

# Description
This Rmarkdown provides a template to explore the biogeography of the plant species included in the NSF project titled "Does Geography Play a Bigger Role Than Species Traits in Explaining Vulnerability of Plants to Global Change?" This includes exploring where the distribution of the Cal Dept. of Fish and Wildlife, Jim Thorne vegetation plots, CalFlora, and GBIF data for each species. It outputs a model data frame that can then be used to build species distribution models in the SDM Models Template.Rmd. 
# Required Datasets:
To run this document, the user needs access to 
1. Environmental Raster Stack: output/predictors/env_stack/CFP_environmental_stack.grd
2. Species Presence/Absence Shapefile (Vegetation Plot Data): data/plots/sp_pres_abs.shp
3. California Florstic Province Shapefile: data/shapefiles/CFP/CFP_GIS.shp
4. GBIF folder (script will create the necessary plot database file from GBIF): data/GBIF/
5. CalFlora data: data/CalFlora/   (I recommend looking through these data first to make sure you kow the species name that is used in the file format, the data were downloaded on 4/17/2020 so this is part of the file name)

```{r load libraries}
suppressWarnings(library(plyr)); suppressWarnings(library(XML)); suppressWarnings(library(sf)); suppressWarnings(library(raster)); suppressWarnings(library(dismo)); 
suppressWarnings(library(rgdal)); suppressWarnings(library(maptools)); suppressWarnings(library(tidyverse)); suppressWarnings(library(rstudioapi)); suppressWarnings(library(ggcorrplot)); suppressWarnings(library(GGally)); suppressWarnings(library(mgcv)); suppressWarnings(library(gam)); 
suppressWarnings(library(ROCR)); suppressWarnings(library(rgbif)); suppressWarnings(library(formula.tools)); suppressWarnings(library(params)); 
suppressWarnings(library(rasterVis)); suppressWarnings(library(viridis)); suppressWarnings(library(cowplot)); suppressWarnings(library(rcartocolor)); 
suppressWarnings(library(caret)); suppressWarnings(library(biomod2));suppressWarnings(library(MASS)); suppressWarnings(library(mgcv)); 
suppressWarnings(library(earth)); suppressWarnings(library(rpart));suppressWarnings(library(mda)); suppressWarnings(library(Hmisc)); 
suppressWarnings(library(randomForest)); suppressWarnings(library(PresenceAbsence)); suppressWarnings(library(gridExtra)); 
suppressWarnings(library(grid)); suppressWarnings(library(kableExtra)); suppressWarnings(library(biomod2)); suppressWarnings(library(MASS)); 
suppressWarnings(library(mgcv)); suppressWarnings(library(earth)); suppressWarnings(library(rpart)); suppressWarnings(library(mda)); 
suppressWarnings(library(Hmisc)) ;suppressWarnings(library(gbm)); suppressWarnings(library(kernlab)); suppressWarnings(library(nnet)); 
suppressWarnings(library(e1071)); suppressWarnings(library(lwgeom)); suppressWarnings(library(patchwork)); suppressWarnings(library(extrafont)); suppressWarnings(library(ggpubr)) 
```

```{r set working directory, eval = FALSE}
# working directory
wd <- list()

# commonly used paths in my working directory 
wd$data   <- "/Users/brookerose/Google Drive/Franklin_grant/project/data/"
wd$output <- "/Users/brookerose/Google Drive/Franklin_grant/project/output/"
wd$scripts <- "/Users/brookerose/Google Drive/Franklin_grant/project/scripts/"
wd$software <- "/Users/brookerose/Google Drive/Franklin_grant/project/software/"
wd$images <- "/Users/brookerose/Google Drive/Franklin_grant/project/images/"
```

```{r include=FALSE}
# working directory
wd <- list()

# commonly used paths in my working directory
wd$data   <- "/Users/Brooke Rose/Google Drive/Franklin_grant/project/data/"
wd$output <- "/Users/Brooke Rose/Google Drive/Franklin_grant/project/output/"
wd$scripts <- "/Users/Brooke Rose/Google Drive/Franklin_grant/project/scripts/"
wd$software <- "/Users/Brooke Rose/Google Drive/Franklin_grant/project/software/"

font_import()
loadfonts(device = "win")
```

# 1. Select target species and create folders for sdm outputs
The "sp" variable should match one of the USDA plant codes for our target species. These are columns within our compiled plot database. The "scien.nm" should be the scientific name of the species. I use this later to download GBIF data for that species. This makes species modeling easier and reduces chance of error. See the species_region_v5_expanded Google Sheets in Shared Drive for the codes

```{r target species}
#sp <- plot.trans$ABMA # this has to come from a variable within plot.trans to work 
sp.code <- 'ABMA'
scien.nm <- 'Abies magnifica'
sp.file.nm <- 'Abies_magnifica'
cal.flor.nm <- 'AbiesMagnifica' # check file and take the part before "_CalFlroa_4_17_2020"

#The code below creates the output folder for the final plot data that will be generated in this Rmarkdown. 

if(!dir.exists(paste0(wd$output, paste('plots/', sp.file.nm, '/', sep='')))){ 
  dir.create(paste0(wd$output, paste('plots/', sp.file.nm, '/', sep='')))
}
```

# 2. Reading the presence/absence data + CFP shapefile
These include all of the Thorne + Cal FWS plot data with environmental data extracted (created in the "plot_environmental_dataframe.Rmd". Here I call in the shapefile, but there is also a csv in the same folder. I also read in the environmental data for a consistent coordinate reference system.

```{r environmental data}
env.stack <- stack(paste0(wd$output, 'predictors/env_stack/BCM1981_2010_CA_CFP_Stack.grd'))
names(env.stack)
```

```{r plot data, include = FALSE}
sp.data <- vroom::vroom(paste0(wd$data, 'plots/sp_pres_abs.gz'))

# as spatial object
sf.data <- sp.data %>% st_as_sf(coords = c('x_coords', 'y_coords'), crs = 3309, remove = FALSE)
sp.trans <- st_transform(sf.data, crs = proj4string(env.stack)) # CRS transformation

cfp <- st_read(paste0(wd$data,'shapefiles/CFP/CFP_GIS_California.shp')) # California Floristic Province shapefile

cfp.trans <- st_transform(cfp, crs = proj4string(env.stack)) # CRS transformation
```

## How many occurrences are there from the vegetation plot data?

```{r presence points}
sp.points <- st_as_sf(subset(sp.trans, ABMA == 1))
nrow(sp.points)
```
# 3. PCA, environmental space

```{r pca_raster funs}
pca_raster <- function(variables, until95 = F) {
  if (class(variables) == "RasterBrick") {
    variables <- stack(variables)
  }
  
  df <- rasterToPoints(variables)
  nas <- !complete.cases(df)
  df[nas,] <- NA
  df <- na.omit(df)
  pca.raw <- df[, -c(1:2)]
  
  #Scale transform
  # this procedure will generate a PCA based on a correlation matrix
  data.scaled <- data.frame(apply(pca.raw, 2, scale))
  
  # Conducto the PCA
  data.pca <- prcomp(data.scaled, retx = TRUE)
  
  #Variance explained for each PC and their coefficient
  varexplained <- round(t(summary(data.pca)$importance), 3)
  varexplained <-
    data.frame(varexplained, round(data.pca$rotation, 3))
  
  if (until95 == T) {
    #axis with cumulative variance explanation until 95%
    var.95 <- varexplained$Cumulative.Proportion <= 0.95
    
    # Creation of new raster with PC
    axis <- as.data.frame(data.pca$x)
    axis <- round(axis[, var.95], 5)
  }
  
  if (until95 == F) {
    #axis until 95% of variance explanation
    # Creation of new raster with PC
    axis <- as.data.frame(data.pca$x)
    axis <- round(axis, 5)
  }
  
  variables2 <- variables[[1]]
  variables3 <- list()
  for (i in 1:ncol(axis)) {
    variables2[!is.na(variables2[])] <- axis[, i]
    variables3[[i]] <- variables2
  }
  
  names(variables3) <- colnames(axis)
  
  variables3 <- stack(variables3)
  return(list(varexplained, variables3))
}
# geom_convexhull
# (function extracted from: https://github.com/cmartin/ggConvexHull/blob/master/R/geom_convexhull.R)
geom_convexhull <-
  function (mapping = NULL,
            data = NULL,
            stat = "convex_hull",
            position = "identity",
            ...,
            na.rm = FALSE,
            show.legend = NA,
            inherit.aes = TRUE) {
    ggplot2::layer(
      data = data,
      mapping = mapping,
      stat = stat,
      geom = ggplot2::GeomPolygon,
      position = position,
      show.legend = show.legend,
      inherit.aes = inherit.aes,
      params = list(na.rm = na.rm, ...)
    )
  }

StatConvexHull <- ggplot2::ggproto(
  "StatConvexHull",
  ggplot2::Stat,
  required_aes = c("x", "y"),
  compute_group = function(self, data, scales, params) {
    data[chull(data$x, data$y), ]
  }
)

stat_convexhull <- function(mapping = NULL, data = NULL, geom = "polygon",
                            position = "identity", show.legend = NA,
                            inherit.aes = TRUE, ...) {
  ggplot2::layer(
    stat = StatConvexHull,
    data = data, mapping = mapping, geom = geom, position = position,
    show.legend = show.legend, inherit.aes = inherit.aes, params = list(...)
  )
}

#' Convex hull geom for ggplot2
#'
#' Convex hull are very similar to polygons (as drawn by geom_polygon) except
#' that only points forming the outside contour are connected by the shape.
#' This function is only a wrapper around R's original chull function
#'
#' @seealso \code{\link[ggplot2]{geom_polygon}}, \code{\link{chull}}
#' @inheritParams ggplot2::geom_polygon
#' @export
#' @examples
#' n <- 10
#' test_df <- data.frame(
#'   a = runif(n),
#'   b = runif(n)
#' )
#'
#' library(ggplot2)
#' ggplot(test_df, aes(x = a,y = b)) +
#'   geom_point() +
#'   geom_convexhull(alpha = 0.7, fill = "red")
#'

geom_convexhull <- function (mapping = NULL, data = NULL, stat = "convex_hull", position = "identity",
                             ..., na.rm = FALSE, show.legend = NA, inherit.aes = TRUE) {
  ggplot2::layer(
    data = data, mapping = mapping, stat = stat, geom = ggplot2::GeomPolygon,
    position = position, show.legend = show.legend, inherit.aes = inherit.aes,
    params = list(na.rm = na.rm, ...)
  )
}
```

```{r pca of environmental raster}
pca_r <- pca_raster(env.stack, until95 = T)

pca_r[[1]] # Information about principal components
pca_r2 <- pca_r[[2]] # Principal components as raster layers
plot(pca_r2)
```

# 4. GBIF data download
The rgbif package allows the user to download species records based on scientific name. Here, I specify that I only want to include observations with coordinates that are located in the United States. I also remove any duplicate observations (same latitude and longitude). I then write that data to file with the date (if it has not been previously downloaded). How many GBIF observations are there?

```{r gbif data}
now <- format(Sys.Date())

if(!dir.exists(paste0(wd$data, paste('GBIF/', sp.file.nm, sep='')))){
  dir.create(paste0(wd$data, paste('GBIF/', sp.file.nm, sep='')))
  sp.gbif <- occ_search(scientificName = scien.nm, return = "data", hasCoordinate = TRUE, country = 'US', basisOfRecord = 'HUMAN_OBSERVATION')
  sp.gbif.dat <- sp.gbif$data
  #filter(is.na(establishmentMeans))
  write_csv(sp.gbif.dat, paste0(wd$data, paste('GBIF/', sp.file.nm, '/', sp.file.nm, '_', now, '.csv', sep='')))
  dups <- duplicated(sp.gbif.dat[c('decimalLatitude', 'decimalLongitude')])
  gbif.uniq <- sp.gbif.dat[!dups,]
  gbif.sf <- st_as_sf(gbif.uniq, coords = c('decimalLongitude', 'decimalLatitude')) %>%
    dplyr::select(key, scientificName, country, geometry)
  st_crs(gbif.sf) <- 4269
  gbif.trans <- st_transform(gbif.sf, crs(cfp.trans))
  st_write(gbif.trans, paste0(wd$data, paste('GBIF/', sp.file.nm, '/', sp.file.nm, '_', now, '.shp', sep='')))
}

sp.shape <- list.files(paste0(wd$data, paste('GBIF/', sp.file.nm, sep='')), pattern = '.shp') # GBIF species shapefile
gbif.sf <- st_read(paste0(wd$data, paste('GBIF/', sp.file.nm, '/', sp.shape, sep = ''))) # reading file
gbif.trans <- st_transform(gbif.sf, crs = proj4string(env.stack))
nrow(gbif.trans)
```

# 5. CalFlora data 
These data were downloaded from the CalFlora website on April 17, 2020. 

```{r calflora}
cal.flora.sp <- read_csv(paste0(wd$data, 'CalFlora/', cal.flor.nm, '_CalFlora_4_17_2020.csv'))
# converting the data frame into a spatial feature
cal.flora.sf <- st_as_sf(cal.flora.sp , coords = c("Longitude", "Latitude")) %>%
  st_set_crs(4008) %>%
  distinct(.keep_all = TRUE) %>%
  mutate(ABMA = 1, # adds the plant code for easy merging later if we want CalFlora data in our presences
         source = "CalFlora",
         survey = "CalFlora") %>%
  st_transform(crs = proj4string(env.stack))
```

## 5a. Extract environmental variables at CalFlora locations 
This is only necessary if you want to add the CalFlora data to our presences. How many CalFlora occurrences are there?

```{r calflora extract}
cal.flora.extract <- raster::extract(x = env.stack, y = cal.flora.sf, df = TRUE, sp = TRUE, cellnumbers = TRUE)
cf.data <- st_as_sf(cal.flora.extract) 
cf.data <- st_transform(cf.data, crs(cfp.trans))
nrow(cf.data)
```

# 6. Map the occurrence data from the three sources

```{r maps}
plot(st_geometry(cfp.trans), col = 'lightyellow', main = paste0(scien.nm, ": Plot Data"))
plot(st_geometry(gbif.trans), add = TRUE, col = 'chocolate1')
plot(st_geometry(cal.flora.sf), add = TRUE, col = 'blue')
plot(st_geometry(sp.points %>% filter(source != 'CalFlora')), add = TRUE, col = 'darkgreen')
legend(-573867, -90000, legend=c("GBIF", "CalFlora", "Vegetation Plots"),
       col=c("chocolate1", "blue", "dark green"), pch = 1, pt.cex=2)
```


# 7. Define study region 
Now, I define the study region by selecting the JEP regions within the CFP that contain occurrences of our target species. This can be done using either the plot data, GBIF, occurrences, or CalFlora data. Ecoregions by study plot subset below:

## 7a. Study region selection based on GBIF data
```{r gbif study region}
gbif.cfp <- st_intersection(gbif.trans, st_make_valid(cfp.trans %>% dplyr::select(JEP_REG)))
gbif.regions <- unique(gbif.cfp$JEP_REG)
gbif.subset <- cfp.trans %>%
  filter(JEP_REG %in% gbif.regions) %>%
  filter(JEP_REG != 'Oregon CFP' & JEP_REG != 'Baja CFP' & JEP_REG != 'Nevada CFP')
plot(st_geometry(cfp.trans), main = paste0(scien.nm, ": Study Regions Based on GBIF"))
plot(st_geometry(gbif.subset),add =TRUE, col = 'chocolate1')
```

## 7b. Study region selection based on CalFlora data
```{r calflora study region}
calf.cfp <- st_intersection(cal.flora.sf, st_make_valid(cfp.trans %>% dplyr::select(JEP_REG)))
calf.regions <- unique(calf.cfp$JEP_REG)
calf.subset <- cfp.trans %>%
  filter(JEP_REG %in% calf.regions) %>%
  filter(JEP_REG != 'Oregon CFP' & JEP_REG != 'Baja CFP' & JEP_REG != 'Nevada CFP')
plot(st_geometry(cfp.trans), main = paste0(scien.nm, ": Study Regions Based on CalFlora"))
plot(st_geometry(calf.subset),add =TRUE, col = 'blue')
```

## 7c. Study region selection based on Vegetation plot data
```{r vegetation plots study region}
veg.cfp <- st_intersection(sp.points, st_make_valid(cfp.trans %>% dplyr::select(JEP_REG)))
veg.regions <- unique(veg.cfp$JEP_REG)
veg.subset <- cfp.trans %>%
  filter(JEP_REG %in% veg.regions) %>%
  filter(JEP_REG != 'Oregon CFP' & JEP_REG != 'Baja CFP' & JEP_REG != 'Nevada CFP')
plot(st_geometry(cfp.trans), main = paste0(scien.nm, ": Study Regions Based on Vegetation Plot Data"))
plot(st_geometry(veg.subset),add =TRUE, col = 'darkgreen')
```

# 8. Exploring plots in environmental space
Here, I explore the vegetation plot data and the CalFlora plots in environmental space. How many presences total?

```{r combining plots}
all.plots <- rbind.fill(cf.data[9:32], sp.trans) %>%
  st_as_sf() %>%
  st_intersection(st_make_valid(calf.subset)) %>%
  dplyr::filter(survey == 'releve' & ABMA == 0 | ABMA== 1) %>%
  mutate(ABMA == ifelse(ABMA ==1, 1, 0)) %>%
  dplyr::rename(clay = percent_clay)

env_conditions <- raster::extract(pca_r2, all.plots) %>% data.frame()
presabs <- dplyr::bind_cols(all.plots, env_conditions) %>% as_tibble()
nrow(presabs %>% filter(ABMA == 1))
```

## Scatter plot with convex hull for different principal components

```{r convex hull plots, include = FALSE}

a <- ggplot(presabs, aes(PC1, PC2)) + 
  geom_point(aes(color=as.factor(survey)), alpha=0.5) +
  #facet_wrap(.~survey, scales = 'free') +
  geom_convexhull(aes(
    color = as.factor(survey),
    fill = as.factor(survey)
  ), alpha = 0.1) +
  labs(title = "PC1 vs. PC2 by survey type") +
  theme_test()+
  theme(title = element_text(color = 'black', size = 20, family = "serif"),
        legend.position = 'bottom', 
        legend.title = element_blank(),
        text = element_text(size = 20, family = "serif", color = 'black'),
        axis.text = element_text(color = 'black', size = 20, family = "serif"))

b <- ggplot(presabs, aes(PC2, PC3)) + 
  geom_point(aes(color=as.factor(survey)), alpha=0.5) +
  #facet_wrap(.~survey, scales = 'free') +
  geom_convexhull(aes(
    color = as.factor(survey),
    fill = as.factor(survey)
  ), alpha = 0.1) +
  labs(title = "PC2 vs. PC3 by survey type")
  theme_test()+
  theme(title = element_text(color = 'black', size = 20, family = "serif"),
        legend.position = 'bottom', 
        legend.title = element_blank(),
        text = element_text(size = 20, family = "serif", color = 'black'),
        axis.text = element_text(color = 'black', size = 20, family = "serif")) 
```

```{r pca plots}
a/b

# Density for each principal component
presabs2 <- tidyr::gather(presabs, "PC1", "PC2", "PC3", value= 'value', key='PC') %>% as_tibble()

ggplot(presabs2, aes(value)) + 
  geom_density(aes(fill=as.factor(survey), color=as.factor(survey)), alpha=0.2)+  
  labs(title = "Density for each principal component") +
  theme_test()+
  theme(title = element_text(color = 'black', size = 20, family = "serif"),
        legend.position = 'bottom', 
        legend.title = element_blank(),
        text = element_text(size = 20, family = "serif", color = 'black'),
        axis.text = element_text(color = 'black', size = 20, family = "serif"))  

```

# 9. Finalizing Plot data
Below, 8a allows you to add the CalFlora data to the original plot data (for species that need more presence data or need more representative data). This step writes a new plot database to file that can then be used for modeling. If the species has sufficient vegetation plot data, skip to 8b. DO NOT RUN BOTH FOR THE SAME SPECIES. You could overwrite data that you intended to preserve. For *Abies magnifica*, I did not add CalFlora data.

## 9a. OPTIONAL: Add CalFlora Plots to plot data - Skipped for *Abies magnifica* 

```{r add calflora, eval = FALSE}
plots.new <- rbind.fill(cf.data[9:32], sp.trans) %>%
    st_as_sf() 
  
study.plots <- st_intersection(plots.new, st_make_valid(calf.subset)) %>%
  dplyr::filter(survey == 'releve' & ABMA == 0 | ABMA== 1) %>%
  mutate(ABMA == ifelse(ABMA ==1, 1, 0)) %>%
  dplyr::rename(clay = percent_clay)

# Below, you can run this code to determine if the there are any duplicate records in your data (Just exploring, does not remove duplicates)
# plot.coords <- do.call(rbind, st_geometry(study.plots)) %>% 
# as_tibble() %>% setNames(c("lon","lat")) %>% unique()
  
dups <- duplicated(study.plots[, c('geometry')])
#sum(dups) # sum of duplicates
plots.unique <- study.plots[!dups,] # keep the records that are _not_ duplicated

sp.points <- st_as_sf(subset(plots.unique, ABMA == 1))
sp.absent <- st_as_sf(subset(plots.unique, ABMA == 0))
paste0(nrow(sp.points), " presence points") # presence points
paste0(nrow(sp.absent), " absence points") # absence points

plot(st_geometry(cfp.trans), main = paste0(scien.nm, ": Presence/Absence Points"))
plot(st_geometry(calf.subset),add =TRUE, col = 'blue')
plot(st_geometry(sp.points), add = TRUE, col = 'green', cex = .6)
plot(st_geometry(sp.absent), add = TRUE, col = 'orange', cex = .4)
  
st_write(plots.unique, paste0(wd$output, paste('plots/', sp.file.nm, '/', 'study_plots', '.shp', sep='')), delete_layer = TRUE)
```

## 9b. Study Plots 
Finally, I only include plot data that are within this study area (I wouldn't want to use absence points from southern California to try and build a model for a species in northern California). This script is dependent on the number of species codes. There could be a less confusing way to do this, but I am not sure how....

```{r study plots, echo = FALSE}
study.plots <- st_intersection(sp.trans, st_make_valid(calf.subset)) %>%
  dplyr::filter(survey == 'releve' & ABMA == 0 | ABMA== 1) %>%
  mutate(ABMA = ifelse(ABMA ==1, 1, 0)) %>% 
  dplyr::rename(clay = percent_clay)

dups <- duplicated(study.plots[, c('geometry')])
#sum(dups) # sum of duplicates
plots.unique <- study.plots[!dups,] # keep the records that are _not_ duplicated

sp.points <- st_as_sf(subset(plots.unique, ABMA == 1))
sp.absent <- st_as_sf(subset(plots.unique, ABMA == 0))
paste0(nrow(sp.points), " presence points") # presence points
paste0(nrow(sp.absent), " absence points") # absence points

plot(st_geometry(cfp.trans), main = paste0(scien.nm, ": Presence/Absence Points"))
plot(st_geometry(calf.subset),add =TRUE, col = 'blue')
plot(st_geometry(sp.points), add = TRUE, col = 'green', cex = .6)
plot(st_geometry(sp.absent), add = TRUE, col = 'orange', cex = .4)


  
st_write(plots.unique, paste0(wd$output, paste('plots/', sp.file.nm, '/', 'study_plots', '.shp', sep='')), delete_layer = TRUE)
```